{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs329s-ml-model-deployment-model-training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTWetPM7AWfY"
      },
      "source": [
        "## Model Building\n",
        "\n",
        "* **Want:** Saved Model format showld be .h5.\n",
        "* **Data:** Different slices of [Food101 dataset](https://www.kaggle.com/dansbecker/food-101).\n",
        "* **Model(s):** [EfficientNetB0](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) backbone's with different output layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk-UIzd_SA5T"
      },
      "source": [
        "## Setting up helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9IdsOGuLYVK"
      },
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Unzip the downloaded file\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Utility function to unzip a zipped file.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_1Ol5LZXrb8"
      },
      "source": [
        "# Setup data inputs\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def create_data_loaders(train_dir, test_dir, image_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Creates a training and test image BatchDataset from train_dir and test_dir.\n",
        "  \"\"\"\n",
        "  train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  # Note: the test data is the same as the previous experiment, we could\n",
        "  # skip creating this, but we'll leave this here to practice.\n",
        "  test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  \n",
        "  return train_data, test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Icsoq0YYRb"
      },
      "source": [
        "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomZoom(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name =\"data_augmentation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn5qDRF8XqLs",
        "outputId": "ef83fb12-64a5-4401-f5da-b1485fb91d3a"
      },
      "source": [
        "# Setup input shape and base model, freezing the base model layers\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\n",
        "  # Fine-tune?\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Add in data augmentation Sequential model as a layer\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  # Give base_model inputs (after augmentation) and don't train it\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  # Pool output features of base model\n",
        "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "\n",
        "  # Put a dense layer on as the output\n",
        "  outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "  # Make a model with inputs and outputs\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5w0PI1pOl7I"
      },
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  if scale:\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIwVrX6vXb4z"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwWwP657Szfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004ed027-ab11-4541-c95d-f912779a8c81"
      },
      "source": [
        "# Get data\n",
        "import zipfile\n",
        "\n",
        "# Download data (10 class subset of Food101 - https://www.kaggle.com/dansbecker/food-101)\n",
        "# Already formatted in standard image classification directory style\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-14 05:54:52--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519184959 (495M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_all_data.zipâ€™\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M  93.4MB/s    in 5.3s    \n",
            "\n",
            "2021-02-14 05:54:58 (93.4 MB/s) - â€˜10_food_classes_all_data.zipâ€™ saved [519184959/519184959]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agzJYtfFBl6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da62030b-260b-479d-e71c-14c20b65b39b"
      },
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2 directories and 1 images in '10_food_classes_all_data'.\n",
            "There are 10 directories and 0 images in '10_food_classes_all_data/train'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/ice_cream'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/ramen'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_wings'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/pizza'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/steak'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/fried_rice'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/hamburger'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/grilled_salmon'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/sushi'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_curry'.\n",
            "There are 10 directories and 0 images in '10_food_classes_all_data/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_curry'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34VT7QiuL7Il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df6609b-3511-466e-9810-3e84a6847d6e"
      },
      "source": [
        "# Check the file in 10_food_classes_10_percent\n",
        "!ls -la 10_food_classes_all_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 28\n",
            "drwxr-xr-x  4 root root 4096 Feb 14 05:54 .\n",
            "drwxr-xr-x  1 root root 4096 Feb 14 05:54 ..\n",
            "-rw-r--r--  1 root root 8196 Feb 14 05:54 .DS_Store\n",
            "drwxr-xr-x 12 root root 4096 Feb 14 05:54 test\n",
            "drwxr-xr-x 12 root root 4096 Feb 14 05:54 train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwxIlyH2B8PG"
      },
      "source": [
        "## That one pesky file that always gets stuck\n",
        "#!rm 10_food_classes_10_percent/.DS_Store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0r-zyagV7Qa"
      },
      "source": [
        "Notice how each of the training directories now has 75 images rather than 750 images. This is key to demonstrating how well transfer learning can perform with less labelled images.\n",
        "\n",
        "The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yamhJ8xJA5x"
      },
      "source": [
        "# Create tensorboard callback (functionized because need to create a new one for each model)\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11TjBJQXdCyZ"
      },
      "source": [
        "Because you're likely to run multiple experiments, it's a good idea to be able to track them in some way.\n",
        "\n",
        "In our case, our function saves a model's performance logs to a directory named `[dir_name]/[experiment_name]/[current_timestamp]`, where:\n",
        "* `dir_name` is the overall logs directory\n",
        "* `experiment_name` is the particular experiment\n",
        "* `current_timestamp` is the time the experiment started based on Python's [`datetime.datetime().now()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.now)\n",
        "\n",
        "> ðŸ”‘ **Note:** Depending on your use case, the above experimenting tracking naming method may work or you might require something more specific. The good news is, the TensorBoard callback makes it easy to track modelling logs as long as you specify where to track them. So you can get as creative as you like with how you name your experiments, just make sure you or your team can understand them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mXArGOXXn6P"
      },
      "source": [
        "## Model 1 (10 classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwrIl-rsLdz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015faef0-2406-4f24-85bc-6a0bf64f8191"
      },
      "source": [
        "# Create BatchDataset\n",
        "train_data, test_data = create_data_loaders(train_dir=\"10_food_classes_all_data/train/\",\n",
        "                                            test_dir=\"10_food_classes_all_data/test/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7500 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_h12Aozqge7",
        "outputId": "530c6a46-be30-4fa3-ad6d-fc76e840eb7c"
      },
      "source": [
        "# What size is our data?\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSo9wTmBy6zr",
        "outputId": "f2b95a59-16f7-4efa-9cda-4b6aced9e961"
      },
      "source": [
        "# Create model\n",
        "model_1 = create_model(num_classes=len(train_data.class_names))\n",
        "\n",
        "# Fit the model\n",
        "history_1_percent = model_1.fit(train_data,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=len(train_data),\n",
        "                    validation_data=test_data,\n",
        "                    validation_steps=int(0.25 * len(test_data)), # validate for less steps\n",
        "                    # Track model training logs\n",
        "                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"all_data_aug\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: transfer_learning/all_data_aug/20210210-231226\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 71s 255ms/step - loss: 1.4620 - accuracy: 0.5484 - val_loss: 0.5066 - val_accuracy: 0.8536\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 50s 211ms/step - loss: 0.7201 - accuracy: 0.7819 - val_loss: 0.4265 - val_accuracy: 0.8569\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 47s 199ms/step - loss: 0.6176 - accuracy: 0.8028 - val_loss: 0.4116 - val_accuracy: 0.8618\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 47s 199ms/step - loss: 0.5606 - accuracy: 0.8227 - val_loss: 0.4060 - val_accuracy: 0.8602\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 45s 189ms/step - loss: 0.5435 - accuracy: 0.8308 - val_loss: 0.3677 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUKJxKVaY3aA",
        "outputId": "2aa249cd-9223-41b7-b9ee-0490b5f49ab0"
      },
      "source": [
        "# Get an image Tensor\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 23:18:11--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2874848 (2.7M) [image/jpeg]\n",
            "Saving to: â€˜03-pizza-dad.jpegâ€™\n",
            "\n",
            "03-pizza-dad.jpeg   100%[===================>]   2.74M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-10 23:18:11 (27.7 MB/s) - â€˜03-pizza-dad.jpegâ€™ saved [2874848/2874848]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3SwO_LAqHAM",
        "outputId": "61055710-bec2-4832-a753-1cb576444c27"
      },
      "source": [
        "# Classes our model is trained on\n",
        "class_names = train_data.class_names\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7gCXuavaDAF",
        "outputId": "2c7775a9-8c87-4409-dcb5-589226d1912d"
      },
      "source": [
        "# Preprocess image\n",
        "pizza_img = load_and_prep_image(\"03-pizza-dad.jpeg\")\n",
        "pizza_img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
              "array([[[ 73.625,  76.75 ,  67.125],\n",
              "        [114.   , 122.   , 101.   ],\n",
              "        [146.875, 151.875, 129.875],\n",
              "        ...,\n",
              "        [ 14.5  ,  17.5  ,  10.5  ],\n",
              "        [ 14.25 ,  19.25 ,  12.25 ],\n",
              "        [ 19.75 ,  22.75 ,  15.75 ]],\n",
              "\n",
              "       [[239.125, 243.625, 246.125],\n",
              "        [225.375, 232.125, 234.875],\n",
              "        [240.   , 245.   , 244.5  ],\n",
              "        ...,\n",
              "        [ 11.   ,  14.   ,   7.   ],\n",
              "        [ 20.   ,  23.   ,  16.   ],\n",
              "        [ 20.875,  25.875,  18.875]],\n",
              "\n",
              "       [[ 32.5  ,  34.5  ,  31.5  ],\n",
              "        [ 44.625,  44.5  ,  42.375],\n",
              "        [ 33.   ,  38.   ,  34.   ],\n",
              "        ...,\n",
              "        [  8.75 ,  13.25 ,   6.25 ],\n",
              "        [ 14.875,  17.875,  10.875],\n",
              "        [ 13.625,  20.625,  12.625]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 61.875,  40.875,  19.875],\n",
              "        [ 60.   ,  42.   ,  22.   ],\n",
              "        [ 61.   ,  43.   ,  21.   ],\n",
              "        ...,\n",
              "        [134.5  ,  96.125,  60.75 ],\n",
              "        [104.875,  69.375,  43.125],\n",
              "        [106.25 ,  75.25 ,  46.25 ]],\n",
              "\n",
              "       [[ 62.75 ,  44.75 ,  24.75 ],\n",
              "        [ 61.125,  43.125,  23.125],\n",
              "        [ 58.125,  40.125,  20.125],\n",
              "        ...,\n",
              "        [159.125, 111.125,  64.625],\n",
              "        [160.375, 112.375,  66.375],\n",
              "        [134.   ,  94.125,  56.75 ]],\n",
              "\n",
              "       [[ 59.625,  42.625,  22.625],\n",
              "        [ 61.75 ,  43.75 ,  22.5  ],\n",
              "        [ 59.25 ,  41.25 ,  21.25 ],\n",
              "        ...,\n",
              "        [161.5  , 113.5  ,  64.5  ],\n",
              "        [159.   , 108.   ,  63.   ],\n",
              "        [155.875, 104.875,  59.875]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81z-ynOlabav",
        "outputId": "4e9ed977-5b2a-4e6d-85e5-9fab2680f8ef"
      },
      "source": [
        "# Make predictions\n",
        "pizza_expanded = tf.expand_dims(pizza_img, axis=0) # expand image dimensions (224, 224, 3) -> (1, 224, 224, 3)\n",
        "pred = model_1.predict(pizza_expanded)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.2119545e-03, 3.3304928e-05, 6.2837714e-04, 1.6367142e-04,\n",
              "        3.0865319e-06, 5.1294103e-07, 9.9020046e-01, 1.2048778e-04,\n",
              "        5.5204531e-05, 5.8289926e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHIoie0Faoin",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6a85e7b-b9f1-42c5-a860-f79b127b8c04"
      },
      "source": [
        "# Check the predicted class\n",
        "class_names[tf.argmax(pred[0])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pizza'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6mNxcPDqwQk"
      },
      "source": [
        "## Save Model 1 \n",
        "\n",
        "We want to save our model in the TensorFlow [`SavedModel`](https://www.tensorflow.org/guide/saved_model) format.\n",
        "\n",
        "We can do this using: \n",
        "`model.save(\"PATH_TO_SAVED_MODEL\")` to create a `SavedModel` object (our trained model).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0jm4Hzdc85u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0e6b61-4624-4e41-bb95-afd58e94f49b"
      },
      "source": [
        "# Save model_1\n",
        "model_1.save(\"efficientnet_model_1_10_classes.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: efficientnet_model_1_10_classes/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}